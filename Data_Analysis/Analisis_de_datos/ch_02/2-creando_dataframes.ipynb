{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de DataFrames\n",
    "Crearemos objetos `DataFrame` a partir de otras estructuras de datos en Python, leyendo un fichero CSV, y consultando una base de datos.\n",
    "\n",
    "## Acerca de los datos\n",
    "En este cuaderno trabajaremos con datos de terremotos del 18 de septiembre de 2018 al 13 de octubre de 2018 (obtenidos del US Geological Survey (USGS) usando la [USGS API](https://earthquake.usgs.gov/fdsnws/event/1/))\n",
    "\n",
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un objeto `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # fijar la semilla para que el resultado sea reproducible\n",
    "pd.Series(np.random.rand(5), name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un objeto `DataFrame` a partir de un objeto `Series`\n",
    "Utilice el método `to_frame()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.linspace(0, 10, num=5)).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un `DataFrame` a partir de Estructuras de Datos Python\n",
    "### A partir de un diccionario de estructuras tipo lista\n",
    "Los valores del diccionario pueden ser listas, matrices NumPy, etc. siempre que tengan longitud (los generadores no tienen longitud por lo que no podemos usarlos aquí):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # fijar la semilla para que el resultado sea reproducible\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'random': np.random.rand(5),\n",
    "        'texto': ['caliente', 'tibio', 'fresco', 'frio', None],\n",
    "        'verdad': [np.random.choice([True, False]) for _ in range(5)]\n",
    "    }, \n",
    "    index=pd.date_range(\n",
    "        end=dt.date(2019, 4, 21),\n",
    "        freq='1D',\n",
    "        periods=5, \n",
    "        name='date'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De una lista de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "    {'mag': 5.2, 'place': 'California'},\n",
    "    {'mag': 1.2, 'place': 'Alaska'},\n",
    "    {'mag': 0.2, 'place': 'California'},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De una lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tuples = [(n, n**2, n**3) for n in range(5)]\n",
    "list_of_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    list_of_tuples, \n",
    "    columns=['n', 'n_cuadrado', 'n_cubo']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De un array NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [2, 4, 8],\n",
    "        [3, 9, 27],\n",
    "        [4, 16, 64]\n",
    "    ]), columns=['n', 'n_cuadrado', 'n_cubo']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un objeto `DataFrame` a partir del contenido de un fichero CSV\n",
    "\n",
    "### Buscando información sobre el fichero antes de leerlo\n",
    "Antes de intentar leer un fichero, podemos usar la línea de comandos para ver información importante sobre el fichero que puede determinar cómo lo leemos. Podemos ejecutar código de línea de comandos desde Jupyter Notebooks (gracias a IPython) usando `!` antes del código.\n",
    "\n",
    "#### Número de líneas (recuento de filas)\n",
    "Por ejemplo, podemos averiguar cuántas líneas hay en el archivo utilizando la utilidad `wc` (recuento de palabras) y contando las líneas del archivo (`-l`). El fichero tiene 9.333 líneas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- DATA\\EARTHQUAKES.CSV: 9333\n"
     ]
    }
   ],
   "source": [
    "# !wc -l data/earthquakes.csv\n",
    "\n",
    "!find /c /v \"\" data\\earthquakes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usuarios de Windows**: si lo anterior no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "```python\n",
    "!find /c /v \"\" data\\earthquakes.csv\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### Tamaño del archivo\n",
    "Podemos encontrar el tamaño del archivo usando `ls` para listar los archivos en el directorio `data`, y pasando las banderas `-lh` para incluir el tamaño del archivo en formato legible por humanos. Luego usamos `grep` para encontrar el fichero en cuestión. Ten en cuenta que `|` pasa el resultado de `ls` a `grep`. La utilidad `grep` se utiliza para encontrar elementos que coincidan con patrones.\n",
    "\n",
    "Esto nos dice que el archivo tiene 3,4 MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/10/2023  18:42         3.524.989 earthquakes.csv\n"
     ]
    }
   ],
   "source": [
    "# !ls -lh data | grep earthquakes.csv\n",
    "\n",
    "!dir data | findstr \"earthquakes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usuarios de Windows**: si lo anterior no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "``python\n",
    "!dir data | findstr \"earthquakes.csv\"\n",
    "```\n",
    "\n",
    "Incluso podemos capturar el resultado de un comando y utilizarlo en nuestro código Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27/10/2023  18:42         3.524.989 earthquakes.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = !dir data\n",
    "[file for file in files if 'earthquake' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usuarios de Windows**: si lo anterior no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "```python\n",
    "files = !dir data\n",
    "[file for file in files if 'earthquake' in file]\n",
    "```\n",
    "\n",
    "\n",
    "#### Examinar algunas filas\n",
    "Podemos utilizar `head` para examinar las `n` primeras filas del fichero. Con la bandera `-n`, podemos especificar cuántas. Esto nos muestra que la primera fila del fichero contiene cabeceras y que están separadas por comas (el hecho de que la extensión del fichero sea `.csv` no significa que contenga valores separados por comas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert,cdi,code,detail,dmin,felt,gap,ids,mag,magType,mmi,net,nst,place,rms,sig,sources,status,time,title,tsunami,type,types,tz,updated,url\n",
      ",,37389218,https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=ci37389218&format=geojson,0.008693,,85.0,\",ci37389218,\",1.35,ml,,ci,26.0,\"9km NE of Aguanga, CA\",0.19,28,\",ci,\",automatic,1539475168010,\"M 1.4 - 9km NE of Aguanga, CA\",0,earthquake,\",geoserve,nearby-cities,origin,phase-data,\",-480.0,1539475395144,https://earthquake.usgs.gov/earthquakes/eventpage/ci37389218\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# !head -n 2 data/earthquakes.csv\n",
    "\n",
    "n = 2\n",
    "with open('data/earthquakes.csv', 'r') as file:\n",
    "    for _ in range(n):\n",
    "        print(file.readline(), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usuarios de Windows**: si lo anterior no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "```python\n",
    "n = 2\n",
    "with open('data/earthquakes.csv', 'r') as file:\n",
    "    for _ in range(n):\n",
    "        print(file.readline(), end='\\r')\n",
    "```\n",
    "\n",
    "\n",
    "Igual que `head` da las filas de arriba, `tail` da las filas de abajo. Esto puede ayudarnos a comprobar que no hay datos extraños en la parte inferior del campo, como quizás algunos metadatos sobre los campos que en realidad no forman parte del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 1 data/earthquakes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usuarios de Windows**: si lo anterior no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "with open('data/earthquakes.csv', 'rb') as file:\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    while file.read(1) != b'\\n':\n",
    "        file.seek(-2, os.SEEK_CUR)\n",
    "    print(file.readline().decode())\n",
    "```\n",
    "\n",
    "*Nota Para inspeccionar más de una fila desde el final del fichero, tendrás que usar esto en su lugar, lo que requiere leer todo el fichero:\n",
    "\n",
    "```python\n",
    "n = 2\n",
    "with open('data/earthquakes.csv', 'r') as file:\n",
    "    print('\\r'.join(file.readlines()[-n:]))\n",
    "```\n",
    "\n",
    "#### Recuento de columnas\n",
    "Podemos utilizar `awk` para encontrar el recuento de columnas. Se trata de una utilidad para escanear y procesar patrones. La bandera `-F` nos permite especificar el delimitador (coma, en este caso). Luego especificamos qué hacer para cada registro del fichero. Elegimos imprimir `NF`, que es una variable predefinida cuyo valor es el número de campos del registro actual. Aquí, decimos `exit` para que imprimamos el número de campos (columnas, aquí) en la primera fila del fichero, y luego nos detenemos.\n",
    "\n",
    "Esto nos dice que tenemos 26 columnas de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -F',' '{print NF; exit}' data/earthquakes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usuarios de Windows**: si lo anterior o lo siguiente no te funciona (depende de tu configuración), utiliza esto en su lugar:\n",
    "\n",
    "```python\n",
    "with open('data/earthquakes.csv', 'r') as file:\n",
    "    print(len(file.readline().split(',')))\n",
    "```\n",
    "\n",
    "\n",
    "Como sabemos que la primera línea del fichero tiene cabeceras, y el fichero está separado por comas, también podemos contar las columnas usando `head` para obtener las cabeceras y analizarlas en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = !head -n 1 data/earthquakes.csv\n",
    "len(headers[0].split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usuarios de Windows**: si tiene que utilizar las alternativas anteriores, considere probar [Cygwin](https://www.cygwin.com) o [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/about).\n",
    "\n",
    "### Lectura del fichero\n",
    "Nuestro fichero es de pequeño tamaño, tiene cabeceras en la primera fila, y está separado por comas, por lo que no necesitamos proporcionar ningún argumento adicional para leer el fichero con `pd.read_csv()`, pero asegúrate de revisar la [documentación](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) para posibles argumentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/earthquakes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas es normalmente muy bueno en averiguar qué opciones utilizar basándose en los datos de entrada, por lo que a menudo no necesitaremos añadir argumentos a la llamada; sin embargo, hay muchas opciones disponibles si las necesitamos, algunas de las cuales incluyen las siguientes:\n",
    "\n",
    "| Parámetro | Propósito |\n",
    "| --- | --- |\n",
    "| `sep` | Especifica el delimitador |\n",
    "| `header` | Número de fila donde se encuentran los nombres de las columnas; la opción por defecto hace que `pandas` deduzca si están presentes |\n",
    "| `names` | Lista de nombres de columnas para utilizar como cabecera |\n",
    "| `index_col` | Columna que se utilizará como índice |\n",
    "| `usecols` | Especifica qué columnas leer |\n",
    "| `dtype` | Especifica los tipos de datos de las columnas | \n",
    "| `converters` | Especifica funciones para convertir datos en determinadas columnas |\n",
    "| `skiprows` | Filas a saltar |\n",
    "| `nrows` | Número de filas a leer a la vez (combinar con `skiprows` para leer un fichero bit a bit) |\n",
    "| `parse_dates` | Convertir automáticamente las columnas que contienen fechas en objetos datetime |\n",
    "| `chunksize` | Para leer el archivo en trozos |\n",
    "| `compression` | Para leer archivos comprimidos sin extraerlos previamente |\n",
    "| `encoding` | Especifica la codificación del archivo |\n",
    "\n",
    "## Escribir un objeto `DataFrame` en un fichero CSV\n",
    "Ten en cuenta que el índice de `df` son sólo números de fila, por lo que no queremos conservarlo. Por lo tanto, pasamos `index=False` al método `to_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escribir un objeto `DataFrame` en una base de datos\n",
    "Fíjate en el parámetro `if_exists`. Por defecto, te dará un error si intentas escribir una tabla que ya existe. Aquí, no nos importa si se sobrescribe. Por último, si estamos interesados en añadir nuevas filas, le damos el valor `'append'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\sol\\documents\\github\\ds_pt_09_2023\\.venv\\lib\\site-packages (2.0.22)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sol\\documents\\github\\ds_pt_09_2023\\.venv\\lib\\site-packages (from SQLAlchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sol\\documents\\github\\ds_pt_09_2023\\.venv\\lib\\site-packages (from SQLAlchemy) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///data/quakes.db')\n",
    "\n",
    "pd.read_csv('data/tsunamis.csv').to_sql(\n",
    "    'tsunamis', engine, index=False, if_exists='replace'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un objeto `DataFrame` consultando una base de datos\n",
    "Usando una base de datos SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>place</th>\n",
       "      <th>magType</th>\n",
       "      <th>mag</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 5.0 - 165km NNW of Flying Fish Cove, Christm...</td>\n",
       "      <td>165km NNW of Flying Fish Cove, Christmas Island</td>\n",
       "      <td>mww</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1539459504090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 6.7 - 262km NW of Ozernovskiy, Russia</td>\n",
       "      <td>262km NW of Ozernovskiy, Russia</td>\n",
       "      <td>mww</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1539429023560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 5.6 - 128km SE of Kimbe, Papua New Guinea</td>\n",
       "      <td>128km SE of Kimbe, Papua New Guinea</td>\n",
       "      <td>mww</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1539312723620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 6.5 - 148km S of Severo-Kuril'sk, Russia</td>\n",
       "      <td>148km S of Severo-Kuril'sk, Russia</td>\n",
       "      <td>mww</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1539213362130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 6.2 - 94km SW of Kokopo, Papua New Guinea</td>\n",
       "      <td>94km SW of Kokopo, Papua New Guinea</td>\n",
       "      <td>mww</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1539208835130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert        type                                              title  \\\n",
       "0   None  earthquake  M 5.0 - 165km NNW of Flying Fish Cove, Christm...   \n",
       "1  green  earthquake            M 6.7 - 262km NW of Ozernovskiy, Russia   \n",
       "2  green  earthquake        M 5.6 - 128km SE of Kimbe, Papua New Guinea   \n",
       "3  green  earthquake         M 6.5 - 148km S of Severo-Kuril'sk, Russia   \n",
       "4  green  earthquake        M 6.2 - 94km SW of Kokopo, Papua New Guinea   \n",
       "\n",
       "                                             place magType  mag           time  \n",
       "0  165km NNW of Flying Fish Cove, Christmas Island     mww  5.0  1539459504090  \n",
       "1                  262km NW of Ozernovskiy, Russia     mww  6.7  1539429023560  \n",
       "2              128km SE of Kimbe, Papua New Guinea     mww  5.6  1539312723620  \n",
       "3               148km S of Severo-Kuril'sk, Russia     mww  6.5  1539213362130  \n",
       "4              94km SW of Kokopo, Papua New Guinea     mww  6.2  1539208835130  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///data/quakes.db')\n",
    "\n",
    "tsunamis = pd.read_sql('SELECT * FROM tsunamis', engine)\n",
    "\n",
    "tsunamis.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div>\n",
    "    <a href=\"./1-pandas_data_estructura.ipynb\">\n",
    "        <button style=\"float: left;\">&#8592; Notebook Anterior</button>\n",
    "    </a>\n",
    "    <a href=\"./3-creando_dataframes_con_api_requests.ipynb\">\n",
    "        <button style=\"float: right;\">Siguiente Notebook &#8594;</button>\n",
    "    </a>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
