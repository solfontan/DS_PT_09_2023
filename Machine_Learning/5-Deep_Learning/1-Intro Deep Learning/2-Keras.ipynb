{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sol\\AppData\\Local\\Temp\\ipykernel_8552\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcAElEQVR4nO3df2zU9R3H8dfxo2eR9rDU9tpRsKDCJlIjg65BGErTUhMjyBZ/JuAMRCxmgL9SoyC4rA4zx3RMs0SpJuIPNn5Es5FhsSVuLQaEEXR2tKlSAi3K1rtSpDD62R+EGydF+B7Xvnvl+UgusXf37r333aVPv9716nPOOQEA0MP6WS8AALg0ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBigPUC39bZ2akDBw4oJSVFPp/Peh0AgEfOObW1tSk7O1v9+p37PKfXBejAgQPKycmxXgMAcJGampo0bNiwc97e6wKUkpIi6dTiqampxtsAALwKh8PKycmJ/Dw/l24L0KpVq/T888+rublZeXl5eumllzRx4sTzzp3+z26pqakECAAS2PleRumWNyG88847Wrx4sZYuXapPPvlEeXl5Ki4u1qFDh7rj4QAACahbAvTCCy9o7ty5uv/++/WDH/xAr7zyigYNGqTXXnutOx4OAJCA4h6g48ePa8eOHSosLPz/g/Trp8LCQtXU1Jx1/46ODoXD4agLAKDvi3uAvv76a508eVKZmZlR12dmZqq5ufms+5eXlysQCEQuvAMOAC4N5r+IWlZWplAoFLk0NTVZrwQA6AFxfxdcenq6+vfvr5aWlqjrW1paFAwGz7q/3++X3++P9xoAgF4u7mdASUlJGj9+vCorKyPXdXZ2qrKyUgUFBfF+OABAguqW3wNavHixZs+erR/+8IeaOHGiVq5cqfb2dt1///3d8XAAgATULQG688479dVXX2nJkiVqbm7WDTfcoE2bNp31xgQAwKXL55xz1kucKRwOKxAIKBQK8UkIAJCALvTnuPm74AAAlyYCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxADrBYDepLOz0/NMR0dHN2wSH6+//npMc+3t7Z5nPvvsM88zK1eu9Dzz5JNPep753e9+53lGkpKTkz3P/PrXv/Y8M3/+fM8zfQFnQAAAEwQIAGAi7gF65pln5PP5oi5jxoyJ98MAABJct7wGdN111+mDDz74/4MM4KUmAEC0binDgAEDFAwGu+NbAwD6iG55DWjv3r3Kzs7WyJEjde+992rfvn3nvG9HR4fC4XDUBQDQ98U9QPn5+aqoqNCmTZv08ssvq7GxUZMnT1ZbW1uX9y8vL1cgEIhccnJy4r0SAKAXinuASkpK9NOf/lTjxo1TcXGx/vznP6u1tVXvvvtul/cvKytTKBSKXJqamuK9EgCgF+r2dwcMGTJE1157rerr67u83e/3y+/3d/caAIBeptt/D+jIkSNqaGhQVlZWdz8UACCBxD1Ajz76qKqrq/XFF1/o73//u2bOnKn+/fvr7rvvjvdDAQASWNz/E9z+/ft199136/Dhw7ryyit10003qba2VldeeWW8HwoAkMDiHqC333473t8SvVQoFPI8c/LkSc8z//jHPzzP/PWvf/U8I0mtra2eZ/7whz/E9Fh9zVVXXeV55pFHHvE88+qrr3qeCQQCnmckafLkyZ5nbrnllpge61LEZ8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ8zjlnvcSZwuGwAoGAQqGQUlNTrde5JOzfvz+muRtuuMHzzH/+85+YHgs9q18/7/9uunnzZs8zycnJnmdikZGREdPc4MGDPc/wyf8X/nOcMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGC9AOwNHTo0prnMzEzPM3wa9ilFRUWeZ2L5/2ndunWeZyTJ7/d7npk6dWpMj4VLF2dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJPowUSk5OjmmuoqLC88wf//hHzzMFBQWeZ2bNmuV5JlY33XST55mNGzd6nklKSvI809zc7HlGkn7729/GNAd4wRkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC55xz1kucKRwOKxAIKBQKKTU11XodxFlHR4fnmVg+hPPJJ5/0PCNJK1as8Dzz4Ycfep6ZMmWK5xkgUVzoz3HOgAAAJggQAMCE5wBt3bpVt912m7Kzs+Xz+bRhw4ao251zWrJkibKyspScnKzCwkLt3bs3XvsCAPoIzwFqb29XXl6eVq1a1eXtK1as0IsvvqhXXnlF27Zt0+WXX67i4mIdO3bsopcFAPQdnv8iaklJiUpKSrq8zTmnlStX6qmnntLtt98uSXrjjTeUmZmpDRs26K677rq4bQEAfUZcXwNqbGxUc3OzCgsLI9cFAgHl5+erpqamy5mOjg6Fw+GoCwCg74trgE7//fnMzMyo6zMzM8/5t+nLy8sVCAQil5ycnHiuBADopczfBVdWVqZQKBS5NDU1Wa8EAOgBcQ1QMBiUJLW0tERd39LSErnt2/x+v1JTU6MuAIC+L64Bys3NVTAYVGVlZeS6cDisbdu2qaCgIJ4PBQBIcJ7fBXfkyBHV19dHvm5sbNSuXbuUlpam4cOHa+HChfrFL36ha665Rrm5uXr66aeVnZ2tGTNmxHNvAECC8xyg7du36+abb458vXjxYknS7NmzVVFRoccff1zt7e2aN2+eWltbddNNN2nTpk267LLL4rc1ACDheQ7Q1KlT9V2fX+rz+bR8+XItX778ohZD3+T3+3vkca644ooeeRxJevHFFz3PTJ482fOMz+fzPAP0ZubvggMAXJoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvOnYQOJYOHChTHNffzxx55n1q9f73nm008/9TwzduxYzzNAb8YZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9ZLnCkcDisQCCgUCik1NdV6HVxi/v3vf3ueGTVqlOeZtLQ0zzMzZszwPDNp0iTPM5I0c+ZMzzM+ny+mx0Lfc6E/xzkDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8GGkwEX6+OOPPc9Mnz7d80woFPI8E6vXXnvN88ysWbM8zwwePNjzDHo/PowUANCrESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmBlgvACS6iRMnep759NNPPc8sWrTI88zatWs9z0jSz372M88zDQ0Nnmcee+wxzzMpKSmeZ9A7cQYEADBBgAAAJjwHaOvWrbrtttuUnZ0tn8+nDRs2RN0+Z84c+Xy+qEssf/sEANC3eQ5Qe3u78vLytGrVqnPeZ/r06Tp48GDk8tZbb13UkgCAvsfzmxBKSkpUUlLynffx+/0KBoMxLwUA6Pu65TWgqqoqZWRkaPTo0Zo/f74OHz58zvt2dHQoHA5HXQAAfV/cAzR9+nS98cYbqqys1K9+9StVV1erpKREJ0+e7PL+5eXlCgQCkUtOTk68VwIA9EJx/z2gu+66K/LP119/vcaNG6dRo0apqqpK06ZNO+v+ZWVlWrx4ceTrcDhMhADgEtDtb8MeOXKk0tPTVV9f3+Xtfr9fqampURcAQN/X7QHav3+/Dh8+rKysrO5+KABAAvH8n+COHDkSdTbT2NioXbt2KS0tTWlpaVq2bJlmzZqlYDCohoYGPf7447r66qtVXFwc18UBAInNc4C2b9+um2++OfL16ddvZs+erZdfflm7d+/W66+/rtbWVmVnZ6uoqEjPPvus/H5//LYGACQ8n3POWS9xpnA4rEAgoFAoxOtBwBmOHTvmeaa2tjamxyosLPQ8E8uPkp/85CeeZ9555x3PM+hZF/pznM+CAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+DRvAWWL58yn//e9/Pc8MGOD5L8Jo9+7dnmdGjx7teQax49OwAQC9GgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvsnAQK4aAcOHPA8s27dOs8zNTU1nmek2D5YNBYTJkzwPHPttdd2wyawwBkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyMFzvDVV195nlm1apXnmdWrV3ue2b9/v+eZntS/f3/PM1dddZXnGZ/P53kGvRNnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT6MFL3ekSNHPM+89957MT3W8uXLPc/861//iumxerNbbrnF88xzzz3neWb8+PGeZ9B3cAYEADBBgAAAJjwFqLy8XBMmTFBKSooyMjI0Y8YM1dXVRd3n2LFjKi0t1dChQzV48GDNmjVLLS0tcV0aAJD4PAWourpapaWlqq2t1ebNm3XixAkVFRWpvb09cp9Fixbpvffe09q1a1VdXa0DBw7ojjvuiPviAIDE5ulNCJs2bYr6uqKiQhkZGdqxY4emTJmiUCikV199VWvWrIm8iLl69Wp9//vfV21trX70ox/Fb3MAQEK7qNeAQqGQJCktLU2StGPHDp04cUKFhYWR+4wZM0bDhw9XTU1Nl9+jo6ND4XA46gIA6PtiDlBnZ6cWLlyoSZMmaezYsZKk5uZmJSUlaciQIVH3zczMVHNzc5ffp7y8XIFAIHLJycmJdSUAQAKJOUClpaXas2eP3n777YtaoKysTKFQKHJpamq6qO8HAEgMMf0i6oIFC/T+++9r69atGjZsWOT6YDCo48ePq7W1NeosqKWlRcFgsMvv5ff75ff7Y1kDAJDAPJ0BOee0YMECrV+/Xlu2bFFubm7U7ePHj9fAgQNVWVkZua6urk779u1TQUFBfDYGAPQJns6ASktLtWbNGm3cuFEpKSmR13UCgYCSk5MVCAT0wAMPaPHixUpLS1NqaqoefvhhFRQU8A44AEAUTwF6+eWXJUlTp06Nun716tWaM2eOJOk3v/mN+vXrp1mzZqmjo0PFxcX6/e9/H5dlAQB9h88556yXOFM4HFYgEFAoFFJqaqr1OvgOZ/4C8oWK5U0m9913n+eZnTt3ep7p7YqKijzPLFu2LKbHmjBhgucZn88X02Oh77nQn+N8FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxPQXUdF7ffPNN55nFi5cGNNjffTRR55nPv/885geqze79dZbPc8sWbLE88wNN9zgeWbgwIGeZ4CewhkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyPtIV988YXnmV/+8peeZz744APPM19++aXnmd5u0KBBMc09++yznmceeughzzNJSUmeZ4C+hjMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEH0baQ/70pz95nnn11Ve7YZP4ufHGGz3P3H333Z5nBgzw/jSdN2+e5xlJuuyyy2KaA+AdZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmfc85ZL3GmcDisQCCgUCik1NRU63UAAB5d6M9xzoAAACYIEADAhKcAlZeXa8KECUpJSVFGRoZmzJihurq6qPtMnTpVPp8v6vLggw/GdWkAQOLzFKDq6mqVlpaqtrZWmzdv1okTJ1RUVKT29vao+82dO1cHDx6MXFasWBHXpQEAic/Tn5rctGlT1NcVFRXKyMjQjh07NGXKlMj1gwYNUjAYjM+GAIA+6aJeAwqFQpKktLS0qOvffPNNpaena+zYsSorK9PRo0fP+T06OjoUDoejLgCAvs/TGdCZOjs7tXDhQk2aNEljx46NXH/PPfdoxIgRys7O1u7du/XEE0+orq5O69at6/L7lJeXa9myZbGuAQBIUDH/HtD8+fP1l7/8RR999JGGDRt2zvtt2bJF06ZNU319vUaNGnXW7R0dHero6Ih8HQ6HlZOTw+8BAUCCutDfA4rpDGjBggV6//33tXXr1u+MjyTl5+dL0jkD5Pf75ff7Y1kDAJDAPAXIOaeHH35Y69evV1VVlXJzc887s2vXLklSVlZWTAsCAPomTwEqLS3VmjVrtHHjRqWkpKi5uVmSFAgElJycrIaGBq1Zs0a33nqrhg4dqt27d2vRokWaMmWKxo0b1y3/AwAAicnTa0A+n6/L61evXq05c+aoqalJ9913n/bs2aP29nbl5ORo5syZeuqppy749Rw+Cw4AElu3vAZ0vlbl5OSourray7cEAFyi+Cw4AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJAdYLfJtzTpIUDoeNNwEAxOL0z+/TP8/PpdcFqK2tTZKUk5NjvAkA4GK0tbUpEAic83afO1+ielhnZ6cOHDiglJQU+Xy+qNvC4bBycnLU1NSk1NRUow3tcRxO4TicwnE4heNwSm84Ds45tbW1KTs7W/36nfuVnl53BtSvXz8NGzbsO++Tmpp6ST/BTuM4nMJxOIXjcArH4RTr4/BdZz6n8SYEAIAJAgQAMJFQAfL7/Vq6dKn8fr/1KqY4DqdwHE7hOJzCcTglkY5Dr3sTAgDg0pBQZ0AAgL6DAAEATBAgAIAJAgQAMJEwAVq1apWuuuoqXXbZZcrPz9fHH39svVKPe+aZZ+Tz+aIuY8aMsV6r223dulW33XabsrOz5fP5tGHDhqjbnXNasmSJsrKylJycrMLCQu3du9dm2W50vuMwZ86cs54f06dPt1m2m5SXl2vChAlKSUlRRkaGZsyYobq6uqj7HDt2TKWlpRo6dKgGDx6sWbNmqaWlxWjj7nEhx2Hq1KlnPR8efPBBo427lhABeuedd7R48WItXbpUn3zyifLy8lRcXKxDhw5Zr9bjrrvuOh08eDBy+eijj6xX6nbt7e3Ky8vTqlWrurx9xYoVevHFF/XKK69o27Ztuvzyy1VcXKxjx4718Kbd63zHQZKmT58e9fx46623enDD7lddXa3S0lLV1tZq8+bNOnHihIqKitTe3h65z6JFi/Tee+9p7dq1qq6u1oEDB3THHXcYbh1/F3IcJGnu3LlRz4cVK1YYbXwOLgFMnDjRlZaWRr4+efKky87OduXl5YZb9bylS5e6vLw86zVMSXLr16+PfN3Z2emCwaB7/vnnI9e1trY6v9/v3nrrLYMNe8a3j4Nzzs2ePdvdfvvtJvtYOXTokJPkqqurnXOn/r8fOHCgW7t2beQ+//znP50kV1NTY7Vmt/v2cXDOuR//+Mfu5z//ud1SF6DXnwEdP35cO3bsUGFhYeS6fv36qbCwUDU1NYab2di7d6+ys7M1cuRI3Xvvvdq3b5/1SqYaGxvV3Nwc9fwIBALKz8+/JJ8fVVVVysjI0OjRozV//nwdPnzYeqVuFQqFJElpaWmSpB07dujEiRNRz4cxY8Zo+PDhffr58O3jcNqbb76p9PR0jR07VmVlZTp69KjFeufU6z6M9Nu+/vprnTx5UpmZmVHXZ2Zm6vPPPzfaykZ+fr4qKio0evRoHTx4UMuWLdPkyZO1Z88epaSkWK9norm5WZK6fH6cvu1SMX36dN1xxx3Kzc1VQ0ODnnzySZWUlKimpkb9+/e3Xi/uOjs7tXDhQk2aNEljx46VdOr5kJSUpCFDhkTdty8/H7o6DpJ0zz33aMSIEcrOztbu3bv1xBNPqK6uTuvWrTPcNlqvDxD+r6SkJPLP48aNU35+vkaMGKF3331XDzzwgOFm6A3uuuuuyD9ff/31GjdunEaNGqWqqipNmzbNcLPuUVpaqj179lwSr4N+l3Mdh3nz5kX++frrr1dWVpamTZumhoYGjRo1qqfX7FKv/09w6enp6t+//1nvYmlpaVEwGDTaqncYMmSIrr32WtXX11uvYub0c4Dnx9lGjhyp9PT0Pvn8WLBggd5//319+OGHUX++JRgM6vjx42ptbY26f199PpzrOHQlPz9fknrV86HXBygpKUnjx49XZWVl5LrOzk5VVlaqoKDAcDN7R44cUUNDg7KysqxXMZObm6tgMBj1/AiHw9q2bdsl//zYv3+/Dh8+3KeeH845LViwQOvXr9eWLVuUm5sbdfv48eM1cODAqOdDXV2d9u3b16eeD+c7Dl3ZtWuXJPWu54P1uyAuxNtvv+38fr+rqKhwn332mZs3b54bMmSIa25utl6tRz3yyCOuqqrKNTY2ur/97W+usLDQpaenu0OHDlmv1q3a2trczp073c6dO50k98ILL7idO3e6L7/80jnn3HPPPeeGDBniNm7c6Hbv3u1uv/12l5ub67755hvjzePru45DW1ube/TRR11NTY1rbGx0H3zwgbvxxhvdNddc444dO2a9etzMnz/fBQIBV1VV5Q4ePBi5HD16NHKfBx980A0fPtxt2bLFbd++3RUUFLiCggLDrePvfMehvr7eLV++3G3fvt01Nja6jRs3upEjR7opU6YYbx4tIQLknHMvvfSSGz58uEtKSnITJ050tbW11iv1uDvvvNNlZWW5pKQk973vfc/deeedrr6+3nqtbvfhhx86SWddZs+e7Zw79Vbsp59+2mVmZjq/3++mTZvm6urqbJfuBt91HI4ePeqKiorclVde6QYOHOhGjBjh5s6d2+f+Ja2r//2S3OrVqyP3+eabb9xDDz3krrjiCjdo0CA3c+ZMd/DgQbulu8H5jsO+ffvclClTXFpamvP7/e7qq692jz32mAuFQraLfwt/jgEAYKLXvwYEAOibCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/wOZOh12/MH8BAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.reshaping.flatten.Flatten object at 0x00000247959780D0>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2201 - accuracy: 0.6969"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.1675 - accuracy: 0.9524 - val_loss: 0.1596 - val_accuracy: 0.9569\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.1581 - accuracy: 0.9551 - val_loss: 0.1549 - val_accuracy: 0.9585\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 0.1497 - accuracy: 0.9573 - val_loss: 0.1508 - val_accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 0.1419 - accuracy: 0.9602 - val_loss: 0.1400 - val_accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.1350 - accuracy: 0.9619 - val_loss: 0.1366 - val_accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 0.1283 - accuracy: 0.9642 - val_loss: 0.1310 - val_accuracy: 0.9659\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.1220 - accuracy: 0.9659 - val_loss: 0.1295 - val_accuracy: 0.9648\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 0.1163 - accuracy: 0.9671 - val_loss: 0.1251 - val_accuracy: 0.9663\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.1117 - accuracy: 0.9689 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 0.1064 - accuracy: 0.9704 - val_loss: 0.1184 - val_accuracy: 0.9675\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 10, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.167549729347229,\n",
       "  0.15807761251926422,\n",
       "  0.1497075855731964,\n",
       "  0.1419122815132141,\n",
       "  0.1350168138742447,\n",
       "  0.12829864025115967,\n",
       "  0.12201866507530212,\n",
       "  0.11630139499902725,\n",
       "  0.11167573928833008,\n",
       "  0.1064416691660881],\n",
       " 'accuracy': [0.9524400234222412,\n",
       "  0.9551399946212769,\n",
       "  0.957319974899292,\n",
       "  0.9601799845695496,\n",
       "  0.9618800282478333,\n",
       "  0.9641799926757812,\n",
       "  0.9658600091934204,\n",
       "  0.9671199917793274,\n",
       "  0.9688599705696106,\n",
       "  0.9704399704933167],\n",
       " 'val_loss': [0.159628227353096,\n",
       "  0.1549234539270401,\n",
       "  0.1508018970489502,\n",
       "  0.13998690247535706,\n",
       "  0.13657571375370026,\n",
       "  0.13103008270263672,\n",
       "  0.12950077652931213,\n",
       "  0.1251143366098404,\n",
       "  0.12022359669208527,\n",
       "  0.11844642460346222],\n",
       " 'val_accuracy': [0.9569000005722046,\n",
       "  0.9585000276565552,\n",
       "  0.9605000019073486,\n",
       "  0.9617999792098999,\n",
       "  0.9631999731063843,\n",
       "  0.9659000039100647,\n",
       "  0.9648000001907349,\n",
       "  0.9663000106811523,\n",
       "  0.9677000045776367,\n",
       "  0.9674999713897705]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.167549729347229,\n",
       "  0.15807761251926422,\n",
       "  0.1497075855731964,\n",
       "  0.1419122815132141,\n",
       "  0.1350168138742447,\n",
       "  0.12829864025115967,\n",
       "  0.12201866507530212,\n",
       "  0.11630139499902725,\n",
       "  0.11167573928833008,\n",
       "  0.1064416691660881],\n",
       " 'accuracy': [0.9524400234222412,\n",
       "  0.9551399946212769,\n",
       "  0.957319974899292,\n",
       "  0.9601799845695496,\n",
       "  0.9618800282478333,\n",
       "  0.9641799926757812,\n",
       "  0.9658600091934204,\n",
       "  0.9671199917793274,\n",
       "  0.9688599705696106,\n",
       "  0.9704399704933167],\n",
       " 'val_loss': [0.159628227353096,\n",
       "  0.1549234539270401,\n",
       "  0.1508018970489502,\n",
       "  0.13998690247535706,\n",
       "  0.13657571375370026,\n",
       "  0.13103008270263672,\n",
       "  0.12950077652931213,\n",
       "  0.1251143366098404,\n",
       "  0.12022359669208527,\n",
       "  0.11844642460346222],\n",
       " 'val_accuracy': [0.9569000005722046,\n",
       "  0.9585000276565552,\n",
       "  0.9605000019073486,\n",
       "  0.9617999792098999,\n",
       "  0.9631999731063843,\n",
       "  0.9659000039100647,\n",
       "  0.9648000001907349,\n",
       "  0.9663000106811523,\n",
       "  0.9677000045776367,\n",
       "  0.9674999713897705]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167550</td>\n",
       "      <td>0.95244</td>\n",
       "      <td>0.159628</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158078</td>\n",
       "      <td>0.95514</td>\n",
       "      <td>0.154923</td>\n",
       "      <td>0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.149708</td>\n",
       "      <td>0.95732</td>\n",
       "      <td>0.150802</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141912</td>\n",
       "      <td>0.96018</td>\n",
       "      <td>0.139987</td>\n",
       "      <td>0.9618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135017</td>\n",
       "      <td>0.96188</td>\n",
       "      <td>0.136576</td>\n",
       "      <td>0.9632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128299</td>\n",
       "      <td>0.96418</td>\n",
       "      <td>0.131030</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122019</td>\n",
       "      <td>0.96586</td>\n",
       "      <td>0.129501</td>\n",
       "      <td>0.9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.116301</td>\n",
       "      <td>0.96712</td>\n",
       "      <td>0.125114</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.111676</td>\n",
       "      <td>0.96886</td>\n",
       "      <td>0.120224</td>\n",
       "      <td>0.9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.106442</td>\n",
       "      <td>0.97044</td>\n",
       "      <td>0.118446</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.167550   0.95244  0.159628        0.9569\n",
       "1  0.158078   0.95514  0.154923        0.9585\n",
       "2  0.149708   0.95732  0.150802        0.9605\n",
       "3  0.141912   0.96018  0.139987        0.9618\n",
       "4  0.135017   0.96188  0.136576        0.9632\n",
       "5  0.128299   0.96418  0.131030        0.9659\n",
       "6  0.122019   0.96586  0.129501        0.9648\n",
       "7  0.116301   0.96712  0.125114        0.9663\n",
       "8  0.111676   0.96886  0.120224        0.9677\n",
       "9  0.106442   0.97044  0.118446        0.9675"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1181 - accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1180650144815445, 0.965499997138977]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sol\\AppData\\Local\\Temp\\ipykernel_8552\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 506ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.995, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sol\\AppData\\Local\\Temp\\ipykernel_8552\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Cargar los datos del Boston Housing dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# housing = fetch_california_housing()\n",
    "# df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "# df['target'] = housing['target']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.745111</td>\n",
       "      <td>11.480198</td>\n",
       "      <td>11.104431</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>6.267082</td>\n",
       "      <td>69.010644</td>\n",
       "      <td>3.740271</td>\n",
       "      <td>9.440594</td>\n",
       "      <td>405.898515</td>\n",
       "      <td>18.475990</td>\n",
       "      <td>354.783168</td>\n",
       "      <td>12.740817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.240734</td>\n",
       "      <td>23.767711</td>\n",
       "      <td>6.811308</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>27.940665</td>\n",
       "      <td>2.030215</td>\n",
       "      <td>8.698360</td>\n",
       "      <td>166.374543</td>\n",
       "      <td>2.200382</td>\n",
       "      <td>94.111148</td>\n",
       "      <td>7.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.874750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.225000</td>\n",
       "      <td>374.672500</td>\n",
       "      <td>6.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.268880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.198500</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>11.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674808</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.609000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.157500</td>\n",
       "      <td>17.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.745111   11.480198   11.104431    0.061881    0.557356    6.267082   \n",
       "std      9.240734   23.767711    6.811308    0.241238    0.117293    0.709788   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081437    0.000000    5.130000    0.000000    0.453000    5.874750   \n",
       "50%      0.268880    0.000000    9.690000    0.000000    0.538000    6.198500   \n",
       "75%      3.674808   12.500000   18.100000    0.000000    0.631000    6.609000   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.725000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.010644    3.740271    9.440594  405.898515   18.475990  354.783168   \n",
       "std     27.940665    2.030215    8.698360  166.374543    2.200382   94.111148   \n",
       "min      2.900000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.077100    4.000000  279.000000   17.225000  374.672500   \n",
       "50%     78.500000    3.142300    5.000000  330.000000   19.100000  391.250000   \n",
       "75%     94.100000    5.118000   24.000000  666.000000   20.200000  396.157500   \n",
       "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.740817  \n",
       "std      7.254545  \n",
       "min      1.730000  \n",
       "25%      6.890000  \n",
       "50%     11.395000  \n",
       "75%     17.092500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "#                                                               housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                      y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 4s 233ms/step - loss: 87.3151 - val_loss: 76.1386\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 66.4425 - val_loss: 66.0877\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 46.6720 - val_loss: 34.7063\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 27.2675 - val_loss: 23.0652\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 20.4170 - val_loss: 18.2697\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 17.0242 - val_loss: 15.7025\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 14.7565 - val_loss: 14.0411\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 13.7051 - val_loss: 13.3092\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 13.3319 - val_loss: 13.0195\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 12.8909 - val_loss: 12.7853\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 12.6040 - val_loss: 12.2469\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 12.0458 - val_loss: 11.9465\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 12.2540 - val_loss: 11.7806\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 12.0281 - val_loss: 12.5187\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 11.5191 - val_loss: 11.0737\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 11.3249 - val_loss: 17.4779\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 11.8577 - val_loss: 10.9230\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 11.0452 - val_loss: 12.9702\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 11.6250 - val_loss: 11.7756\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 10.7974 - val_loss: 11.6896\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_absolute_percentage_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                420       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 451\n",
      "Trainable params: 451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 14.2756\n",
      "14.275640487670898\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.6136446],\n",
       "       [18.02509  ],\n",
       "       [21.508638 ],\n",
       "       [26.575651 ],\n",
       "       [24.990385 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = tf.keras.models.load_model(\"callback_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 13.3583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.358282089233398"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.3934\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.2467\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.1358\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5841\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 10.1790\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.8055\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.7647\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.7816\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.4840\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 10.2333\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.7262\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5622\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.1173\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.3968\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.6576\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.3710\n",
      "Epoch 17/30\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.4737"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\keras\\engine\\training.py:1376\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1374\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1376\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m         epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m         step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m         _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\keras\\engine\\data_adapter.py:1246\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1246\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1247\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1248\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[0;32m   1251\u001b[0m     original_spe)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    676\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\jamr1\\miniconda3\\envs\\gym2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 9.3253 - val_loss: 14.1833\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.1761 - val_loss: 12.3861\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.7355 - val_loss: 15.4178\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.8083 - val_loss: 12.9600\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 9.4095 - val_loss: 12.3090\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 9.0876 - val_loss: 13.5602\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 8.9169 - val_loss: 12.9708\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 9.3044 - val_loss: 12.8442\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.6792 - val_loss: 14.4303\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.2458 - val_loss: 12.6842\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, )\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=2000,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
