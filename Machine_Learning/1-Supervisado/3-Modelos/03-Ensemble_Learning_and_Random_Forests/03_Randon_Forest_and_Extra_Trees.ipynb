{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Capitulo 6 – Ensemble Learning and Random Forests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hicimos en NoteBooks anteriores, vamos a definir los tamaños de fuente por defecto para que las figuras queden más bonitas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vamos a crear la carpeta `images/ensembles` (si no existe ya), y definir la función `save_fig()` que se utiliza a través de este Notebook para guardar las figuras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"ensembles\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches and Random Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase BaggingClassifier también admite el muestreo de las características. El muestreo se controla mediante dos hiperparámetros: max_features y bootstrap_features. Funcionan del mismo modo que max_sample y bootstrap, pero para el muestreo de características en lugar del muestreo de instancias. Así, cada predictor se entrenará con un subconjunto aleatorio de las características de entrada.\n",
    "\n",
    "Esta técnica es especialmente útil cuando se trabaja con entradas de alta dimensión (como imágenes), ya que puede acelerar considerablemente el entrenamiento. El muestreo tanto de las instancias de entrenamiento como de las características se denomina método de parches aleatorios. Mantener todas las instancias de entrenamiento (estableciendo bootstrap=False y max_samples=1.0) pero muestrear las características (estableciendo bootstrap_features a True y/o max_features a un valor menor que 1.0) se denomina método de subespacios aleatorios.\n",
    "\n",
    "El muestreo de características da como resultado una mayor diversidad de predictores, cambiando un poco más de sesgo por una menor varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos comentado, un random forest es un conjunto de árboles de decisión, generalmente entrenados mediante el método bagging (o a veces pasting), normalmente con max_samples fijado al tamaño del conjunto de entrenamiento. En lugar de construir un BaggingClassifier y pasarle un DecisionTreeClassifier, puedes usar la clase RandomForestClassifier, que es más conveniente y está optimizada para árboles de decisión (de forma similar, hay una clase RandomForestRegressor para tareas de regresión). El siguiente código entrena un clasificador de random forest con 500 árboles, cada uno limitado a un máximo de 16 nodos hoja, utilizando todos los núcleos de CPU disponibles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,\n",
    "                                 n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con algunas excepciones, un RandomForestClassifier tiene todos los hiperparámetros de un DecisionTreeClassifier (para controlar cómo crecen los árboles), además de todos los hiperparámetros de un BaggingClassifier para controlar el conjunto en sí.\n",
    "\n",
    "El algoritmo de random forest introduce una aleatoriedad adicional en el crecimiento de los árboles; en lugar de buscar la mejor característica al dividir un nodo, busca la mejor característica entre un subconjunto aleatorio de características. Por defecto, muestrea n características (donde n es el número total de características). El algoritmo da como resultado una mayor diversidad del árbol, que (de nuevo) cambia un mayor sesgo por una menor varianza, lo que generalmente produce un modelo globalmente mejor. Así pues, el siguiente BaggingClassifier es equivalente al anterior RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un Random Forest equivale a una bolsa de árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bag_clf.predict(X_test)\n",
    "np.all(y_pred_bag == y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se hace crecer un árbol en un random forest, en cada nodo sólo se considera un subconjunto aleatorio de las características para la división (como se ha comentado antes). Es posible hacer árboles aún más aleatorios utilizando también umbrales aleatorios para cada característica en lugar de buscar los mejores umbrales posibles (como hacen los árboles de decisión normales). Para ello, basta con establecer splitter=\"random\" al crear un DecisionTreeClassifier.\n",
    "\n",
    "Un bosque de estos árboles extremadamente aleatorios se denomina conjunto de árboles extremadamente aleatorios (o extra-árboles para abreviar). Una vez más, esta técnica cambia un mayor sesgo por una menor varianza. También hace que los clasificadores extra-árboles sean mucho más rápidos de entrenar que los random forest normales, porque encontrar el mejor umbral posible para cada característica en cada nodo es una de las tareas que más tiempo consume en el crecimiento de un árbol. Puede crear un clasificador extra-trees utilizando la clase ExtraTreesClassifier de Scikit-Learn. Su API es idéntica a la de la clase RandomForestClassifier, excepto que el valor predeterminado de bootstrap es False. Del mismo modo, la clase ExtraTreesRegressor tiene la misma API que la clase RandomForestRegressor, excepto que el valor predeterminado de bootstrap es False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es difícil saber de antemano si un RandomForestClassifier funcionará mejor o peor que un ExtraTreesClassifier. Por lo general, la única forma de saberlo es probar ambos y compararlos mediante cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra gran cualidad de los Random Forest es que facilitan la medición de la importancia relativa de cada característica. Scikit-Learn mide la importancia de una característica observando en qué medida los nodos del árbol que utilizan esa característica reducen la impureza de media, en todos los árboles del bosque. Más concretamente, se trata de una media ponderada, en la que el peso de cada nodo es igual al número de muestras de entrenamiento asociadas a él.\n",
    "\n",
    "Scikit-Learn calcula esta puntuación automáticamente para cada característica después del entrenamiento, y luego escala los resultados para que la suma de todas las importancias sea igual a 1. Puede acceder al resultado utilizando la variable feature_importances_. Por ejemplo, el siguiente código entrena un RandomForestClassifier en el conjunto de datos del iris y muestra la importancia de cada característica. Parece que las características más importantes son la longitud (44%) y la anchura (42%) de los pétalos, mientras que la longitud y la anchura de los sépalos son poco importantes en comparación (11% y 2%, respectivamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11 sepal length (cm)\n",
      "0.02 sepal width (cm)\n",
      "0.44 petal length (cm)\n",
      "0.42 petal width (cm)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris.data, iris.target)\n",
    "for score, name in zip(rnd_clf.feature_importances_, iris.data.columns):\n",
    "    print(round(score, 2), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, si se entrena un clasificador de random forest en el conjunto de datos MNIST y se representa gráficamente la importancia de cada píxel, se obtiene la imagen representada en la Figura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X_mnist, y_mnist = fetch_openml('mnist_784', return_X_y=True, as_frame=False,\n",
    "                                parser='auto')\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_clf.fit(X_mnist, y_mnist)\n",
    "\n",
    "heatmap_image = rnd_clf.feature_importances_.reshape(28, 28)\n",
    "plt.imshow(heatmap_image, cmap=\"hot\")\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\n",
    "                           rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'], fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "save_fig(\"mnist_feature_importance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los random forest son muy útiles para comprender rápidamente qué características son realmente importantes, en particular si necesita realizar una selección de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
